{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb58ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m im\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import cv2\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image as im\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "#from tf.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from PIL import Image as im\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab514a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining constants successful!\n"
     ]
    }
   ],
   "source": [
    "IMAGE_WIDTH = 224    \n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "\n",
    "# Path where our data is located\n",
    "base_path = \"garbage_classification/\"\n",
    "\n",
    "\n",
    "# Dictionary to save our 12 classes\n",
    "categories = {0: 'paper', 1: 'cardboard', 2: 'plastic', 3: 'metal', 4: 'trash', 5: 'green-glass'}\n",
    "\n",
    "print('defining constants successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34490482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements =  4901\n"
     ]
    }
   ],
   "source": [
    "def add_class_name_prefix(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(lambda x: x[:re.search(\"\\d\",x).start()] + '/' + x)\n",
    "    return df\n",
    "\n",
    "# list conatining all the filenames in the dataset\n",
    "filenames_list = []\n",
    "# list to store the corresponding category, note that each folder of the dataset has one class of data\n",
    "categories_list = []\n",
    "\n",
    "for category in categories:\n",
    "    filenames = os.listdir(base_path + categories[category])\n",
    "    \n",
    "    filenames_list = filenames_list  +filenames\n",
    "    categories_list = categories_list + [category] * len(filenames)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames_list,\n",
    "    'category': categories_list\n",
    "})\n",
    "\n",
    "df = add_class_name_prefix(df, 'filename')\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print('number of elements = ' , len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39bdc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plastic/plastic658.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>green-glass/green-glass531.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plastic/plastic657.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardboard/cardboard646.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trash/trash85.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  category\n",
       "0          plastic/plastic658.jpg         2\n",
       "1  green-glass/green-glass531.jpg         5\n",
       "2          plastic/plastic657.jpg         2\n",
       "3      cardboard/cardboard646.jpg         1\n",
       "4               trash/trash85.jpg         4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32f5f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32mC:\\Users\\DataLeticia\\miniconda3\\envs\\keras3\\Lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\Users\\DataLeticia\\miniconda3\\envs\\keras3\\Lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mC:\\Users\\DataLeticia\\miniconda3\\envs\\keras3\\Lib\\site-packages\\keras\\engine\\functional.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c7fd7b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m random_row \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m sample \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[random_row]\n\u001b[1;32m----> 3\u001b[0m randomimage \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(base_path \u001b[38;5;241m+\u001b[39msample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "random_row = random.randint(0, len(df)-1)\n",
    "sample = df.iloc[random_row]\n",
    "randomimage = image.load_img(base_path +sample['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30968c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visualization = df.copy()\n",
    "# Change the catgegories from numbers to names\n",
    "df_visualization['category'] = df_visualization['category'].apply(lambda x:categories[x] )\n",
    "\n",
    "df_visualization['category'].value_counts().plot.bar(x = 'count', y = 'category' )\n",
    "\n",
    "plt.xlabel(\"Garbage Classes\", labelpad=14)\n",
    "plt.ylabel(\"Images Count\", labelpad=14)\n",
    "plt.title(\"Count of images per class\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2493c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace(categories) \n",
    "\n",
    "# We first split the data into two sets and then split the validate_df to two sets\n",
    "train_df, validate_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "validate_df, test_df = train_test_split(validate_df, test_size=0.3, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print('train size = ', total_validate , 'validate size = ', total_validate, 'test size = ', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    \n",
    "    ###  Augmentation Start  ###\n",
    "    \n",
    "    rotation_range=30,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    "    \n",
    "    ##  Augmentation End  ###\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49733924",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50271ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    base_path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_df.category.unique()\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49116425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(9):\n",
    "    random_row = random.randint(0, len(df)-1)\n",
    "    sample = df.iloc[random_row]\n",
    "    random_image = tf.keras.utils.load_img(base_path + sample['filename'])\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.title(sample['category'])\n",
    "    plt.imshow(random_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=\"category\", data=df, palette='Blues')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20203fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
    "base_model = tf.keras.applications.VGG16(input_shape = IMG_SHAPE,\n",
    "                                         include_top = False,\n",
    "                                         weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a9e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_layer_trainable():\n",
    "    for layer in base_model.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320da6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30169907",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_layer_trainable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    #layers.CenterCrop(125, 125),\n",
    "    keras.layers.RandomFlip('horizontal', input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
    "    keras.layers.RandomRotation(0.2, fill_mode = 'nearest'),\n",
    "    keras.layers.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    keras.layers.Rescaling(1./255),\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(n_classes, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df97c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights.hdf5', save_best_only = True, verbose = 0)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True, mode = 'min')\n",
    "\n",
    "#ReduceLROnPlateau to stabilize the training process of the model\n",
    "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs = 20,\n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = [tl_checkpoint_1, early_stop, rop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb74851",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(20)\n",
    "\n",
    "plt.figure(figsize = (20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461956d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe= test_df,\n",
    "    directory=base_path,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=1,\n",
    "    shuffle=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7048b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "_, accuracy = model.evaluate_generator(test_generator, nb_samples)\n",
    "\n",
    "print('Accuracy on test set = ',  round((accuracy * 100),2 ), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_label_map = test_generator.class_indices\n",
    "gen_label_map = dict((v,k) for k,v in gen_label_map.items())\n",
    "print(gen_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# get the model's predictions for the test set\n",
    "preds = model.predict_generator(test_generator, nb_samples)\n",
    "\n",
    "# Get the category with the highest predicted probability, the prediction is only the category's number and not name\n",
    "preds = preds.argmax(1)\n",
    "\n",
    "# Convert the predicted category's number to name \n",
    "preds = [gen_label_map[item] for item in preds]\n",
    "\n",
    "# Convert the pandas dataframe to a numpy matrix\n",
    "labels = test_df['category'].to_numpy()\n",
    "\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fba865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune  = base_model\n",
    "fine_tune.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in fine_tune.layers:\n",
    "    # Boolean whether this layer is trainable.\n",
    "    trainable = ('block5' in layer.name or 'block4' in layer.name)\n",
    "    \n",
    "    # Set the layer's bool.\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1647f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)\n",
    "\n",
    "model2 = Sequential([\n",
    "    data_augmentation,\n",
    "    keras.layers.Rescaling(1./255),\n",
    "    fine_tune,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(n_classes, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81be2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea13c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70768deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Chackpoint\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights_fine_tuning.hdf5', save_best_only = True, verbose = 0)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True, mode = 'min')\n",
    "\n",
    "#ReduceLROnPlateau to stabilize the training process of the model\n",
    "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 0.000001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras6",
   "language": "python",
   "name": "keras6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
